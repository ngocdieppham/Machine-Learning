{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6ae4931",
   "metadata": {},
   "source": [
    "# $K$-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641fb442",
   "metadata": {},
   "source": [
    "The $K$-Nearest Neighbors (KNN) is a simple machine learning algorithm that can be used for both regression and classification. It works by finding the nearest $K$ neighbors of an observation and using those neighboring points to make a prediction. KNN naturally handles multiclassification problems. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e38441",
   "metadata": {},
   "source": [
    "## Finding the neighbors\n",
    "\n",
    "The KNN model makes predictions by determining the $K$ neighbors of test points from a training set. The neighbors are the $K$ training points that are closest to the test point, using distance as the metric. Commonly, the Euclidean distance is used but other distance metrics work as well. The generalized distance metric is called the Minkowski distance, defined as \n",
    "\n",
    "$$ d_j = \\left(\\sum_{i} \\left |x_i - X_{ji}\\right |^{p} \\right)^{1/p}, $$\n",
    "\n",
    "where $d_j$ is the distance between training point $j$ to the point $x_i$ and $p$ is an integer. When $p=2$, the Minkowski distance is the just the standard Euclidean distance. With the $K$ neighbors identified, the algorithm can make a prediction with the label values of the neighbors. For regression, the predicted value is the mean of the $K$ neighbors. For classification, the predicted label is the class with the plurality, i.e., which class is most represented among the neighbors.\n",
    "\n",
    "Since the KNN model calculates distances, the data set needs to be scaled for the model to work properly. All the features should have a similar scale. The scaling can be accomplished by using the `StandardScaler` transformer.\n",
    "\n",
    "We will demonstrate the usage of the KNN algorithm with the iris data set. For visualization purposes, we will only use two of the four features, just the petal width and length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4391758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import neighbors, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba0a02c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 3\n",
      "Number of data points: 150\n",
      "\n",
      "Samples from class 0:\n",
      " [[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "\n",
      "Samples from class 1:\n",
      " [[7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]]\n",
      "\n",
      "Samples from class 2:\n",
      " [[6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]]\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "iris_X = iris.data\n",
    "iris_y = iris.target\n",
    "#print(iris)\n",
    "#print(iris_X)\n",
    "#print(iris_y)\n",
    "print('Number of classes: %d' %len(np.unique(iris_y)))\n",
    "print('Number of data points: %d' %len(iris_y))\n",
    "\n",
    "\n",
    "X0 = iris_X[iris_y == 0,:]\n",
    "print('\\nSamples from class 0:\\n', X0[:5,:])\n",
    "\n",
    "X1 = iris_X[iris_y == 1,:]\n",
    "print('\\nSamples from class 1:\\n', X1[:5,:])\n",
    "\n",
    "X2 = iris_X[iris_y == 2,:]\n",
    "print('\\nSamples from class 2:\\n', X2[:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fd5fcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 100\n",
      "Test size    : 50\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     iris_X, iris_y, test_size=50)\n",
    "\n",
    "print(\"Training size: %d\" %len(y_train))\n",
    "print(\"Test size    : %d\" %len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a4f11a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print results for 20 test data points:\n",
      "Predicted labels:  [2 0 2 1 1 0 2 1 2 0 1 2 2 1 1 1 1 1 1 1]\n",
      "Ground truth    :  [1 0 1 1 1 0 2 1 2 0 1 2 2 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "clf = neighbors.KNeighborsClassifier(n_neighbors = 1, p = 2)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Print results for 20 test data points:\")\n",
    "print(\"Predicted labels: \", y_pred[20:40])\n",
    "print(\"Ground truth    : \", y_test[20:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ec18eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 1NN: 92.00 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy of 1NN: %.2f %%\" %(100*accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7e3ec68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 10NN with major voting: 98.00 %\n"
     ]
    }
   ],
   "source": [
    "clf = neighbors.KNeighborsClassifier(n_neighbors = 10, p = 2)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy of 10NN with major voting: %.2f %%\" %(100*accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "914ffd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 10NN (1/distance weights): 96.00 %\n"
     ]
    }
   ],
   "source": [
    "clf = neighbors.KNeighborsClassifier(n_neighbors = 10, p = 2, weights = 'distance')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy of 10NN (1/distance weights): %.2f %%\" %(100*accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e1bffaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 10NN (customized weights): 96.00 %\n"
     ]
    }
   ],
   "source": [
    "def myweight(distances):\n",
    "    sigma2 = .5 # we can change this number\n",
    "    return np.exp(-distances**2/sigma2)\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors = 10, p = 2, weights = myweight)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy of 10NN (customized weights): %.2f %%\" %(100*accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b4a4fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
