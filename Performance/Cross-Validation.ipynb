{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82a3ffcd",
   "metadata": {},
   "source": [
    "# Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2f7d87",
   "metadata": {},
   "source": [
    "One way to evaluate the Decision Tree model would be to use the train_test_split() function to split the training set into a smaller training set and a validation set, then train your models against the smaller training set and evaluate them against the validation set. \n",
    "\n",
    "A great alternative is to use Scikit-Learn's K-fold cross-validation feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efddb216",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stratified sampling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "data_housing = fetch_california_housing()\n",
    "df = pd.DataFrame(data_housing.data, columns = data_housing.feature_names)\n",
    "df['AvgHouseVal'] = data_housing.target\n",
    "df['income_categorical'] = pd.cut(df['MedInc'], bins=[0., 1.5,3.0,4.5,6.,np.inf], labels=[1,2,3,4,5])\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(df, df['income_categorical']):\n",
    "    strat_train_set = df.loc[train_index]\n",
    "    strat_test_set = df.loc[test_index]\n",
    "for i in (strat_train_set,strat_test_set):\n",
    "    i.drop('income_categorical', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7339f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "housing = strat_train_set.drop('AvgHouseVal', axis=1)\n",
    "housing_label = strat_train_set['AvgHouseVal'].copy()\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('imp', SimpleImputer(strategy = 'median')),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "housing_prepared = pipe.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e990853",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7aa11c",
   "metadata": {},
   "source": [
    "The following code randomly splits the training set into 10 distinct subsets called \"folds\", then it trains and evaluates the Decision Tree model 10 times, picking a different fold for evaluation every time and training on the other 9 folds. The result is an array containing the 10 evaluation scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "848ef44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  [0.70454858 0.71450523 0.73217492 0.7347886  0.71205754 0.73100768\n",
      " 0.75472167 0.70973704 0.71566895 0.75309291]\n",
      "Mean:  0.7262303109285979\n",
      "Standard deviation:  0.0169019981522679\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "score_tree_reg = cross_val_score(tree_reg, housing_prepared, housing_label,\n",
    "                         scoring='neg_mean_squared_error',cv=10)\n",
    "print('RMSE: ', np.sqrt(-score_tree_reg))\n",
    "print('Mean: ', np.sqrt(-score_tree_reg).mean())\n",
    "print('Standard deviation: ', np.sqrt(-score_tree_reg).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc43964f",
   "metadata": {},
   "source": [
    "Cross-Validation features expect a utility function, it means, greater is better, so the scoring function is actually the opposite of MSE, which is why the preceding code computes -scores before calculating the squared root. And notice that cross-validation allows you to get not only an estimate of the performance of your model, but also a measure of how precise this estimate is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5c30808",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6611436f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  [0.7036911  0.72431503 0.72680092 0.73050519 0.75637811 0.74775988\n",
      " 0.68872509 0.73301589 0.76535004 0.72080567]\n",
      "Mean:  0.7297346932386132\n",
      "Standard deviation:  0.021891450608441578\n"
     ]
    }
   ],
   "source": [
    "score_lin_reg = cross_val_score(lin_reg, housing_prepared, housing_label,\n",
    "                         scoring='neg_mean_squared_error',cv=10)\n",
    "print('RMSE: ', np.sqrt(-score_lin_reg))\n",
    "print('Mean: ', np.sqrt(-score_lin_reg).mean())\n",
    "print('Standard deviation: ', np.sqrt(-score_lin_reg).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0f55c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55a2052c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  [0.49643739 0.48169674 0.5011856  0.5344223  0.49843895 0.54235484\n",
      " 0.49470303 0.49194622 0.54107729 0.51841869]\n",
      "Mean:  0.510068104450364\n",
      "Standard deviation:  0.021062328065974228\n"
     ]
    }
   ],
   "source": [
    "score_forest_reg = cross_val_score(forest_reg, housing_prepared, housing_label,\n",
    "                         scoring='neg_mean_squared_error',cv=10)\n",
    "print('RMSE: ', np.sqrt(-score_forest_reg))\n",
    "print('Mean: ', np.sqrt(-score_forest_reg).mean())\n",
    "print('Standard deviation: ', np.sqrt(-score_forest_reg).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0b1cf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
