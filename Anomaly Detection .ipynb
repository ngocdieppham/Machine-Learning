{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e01dfdbe",
   "metadata": {},
   "source": [
    "## Anomaly Detection Using Gaussian Mixtures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61530a29",
   "metadata": {},
   "source": [
    "Anomaly detection (also called outlier detection) is the task of detecting instances that deviate strongly from the norm. These instances are called anomalies, or outliers, while the normal instances are called inliers. Anomaly detection is useful in a wide variety of applications, such as fraud detection, detecting defective products in manufacturing, or removing outliers from a dataset before training another model (which can significantly improve the performance of the resulting model) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abca0332",
   "metadata": {},
   "source": [
    "Using a Gaussian mixtrure model for anomaly detection is quite simple: any instance located in a low-density region can be considered an anomaly. We must define what density threshold we want to use.\n",
    "\n",
    "For example, in a manufacturing company that tries to detect defective products, the ratio of defective products is usually well known. Say it is equal to 4%. We then set the density threshold to be the value that results in having 4% of the instances located in areas below that threshold density. If we notice that we get too many false positives (perfectly good products that are flagged as defective), you can lower the threshold. Conversely, if you have too many false negative (defective products that the system does not flag as defective), we can increase the threshold. This is the precision/recall trade-off. \n",
    "\n",
    "Here is how we would identify the outliers using the fourth percentile lowest density as the threshold (e.g., approximately 4% of the instances will be flagged as anomolies):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2d6290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=1000, noise=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48c510e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianMixture(n_components=3, n_init=10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "gm = GaussianMixture(n_components=3, n_init=10)\n",
    "gm.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c2419d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.19704522, -0.50773101],\n",
       "       [-0.96905764, -0.0578824 ],\n",
       "       [ 1.97825049,  0.56418079],\n",
       "       [-0.95043252,  0.05939401],\n",
       "       [-0.2120919 ,  0.95138865],\n",
       "       [ 1.9545389 ,  0.44903743],\n",
       "       [ 1.23300595, -0.48006507],\n",
       "       [ 2.03574676,  0.52792933],\n",
       "       [ 1.19453439, -0.53022682],\n",
       "       [-1.0597144 , -0.06641306],\n",
       "       [ 1.30395244, -0.38341852],\n",
       "       [ 1.19058025, -0.4704052 ],\n",
       "       [-0.96738628,  0.00993892],\n",
       "       [ 0.99580937,  0.55454215],\n",
       "       [-1.02637829,  0.00731303],\n",
       "       [ 1.20032629, -0.45974999],\n",
       "       [ 1.37180184, -0.29016988],\n",
       "       [ 1.23513236, -0.40915604],\n",
       "       [ 1.26437352, -0.34235832],\n",
       "       [ 1.99148518,  0.57083883],\n",
       "       [ 1.99913375,  0.53707771],\n",
       "       [-1.00727314, -0.00930005],\n",
       "       [-0.13979   ,  1.06240234],\n",
       "       [-0.94209061,  0.04002852],\n",
       "       [-0.20671228,  0.90729231],\n",
       "       [-0.10545596,  1.12512775],\n",
       "       [-0.22264224,  0.94535617],\n",
       "       [-0.22732885,  0.92276511],\n",
       "       [ 1.28827615, -0.36721488],\n",
       "       [ 1.29243927, -0.39338014],\n",
       "       [-0.93216033,  0.03242345],\n",
       "       [ 1.23607838, -0.38280745],\n",
       "       [-0.9490165 ,  0.06896198],\n",
       "       [ 2.10645268,  0.56796635],\n",
       "       [-0.93785668,  0.06547412],\n",
       "       [ 1.99648158,  0.54323982],\n",
       "       [-0.99408324,  0.03480111],\n",
       "       [-0.2188514 ,  0.94156633],\n",
       "       [ 1.29354184, -0.38204322],\n",
       "       [ 1.9107178 ,  0.40337372]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "densities = gm.score_samples(X)\n",
    "density_threshold = np.percentile(densities, 4)\n",
    "anomalies = X[densities < density_threshold]\n",
    "anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea45b93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
