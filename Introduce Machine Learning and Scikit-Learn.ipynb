{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dd623e9",
   "metadata": {},
   "source": [
    "## What is Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d3de4a",
   "metadata": {},
   "source": [
    "Machine learning (ML) is a process of building models that learn from data. Machine learning models are algorithms that learn patterns from data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dd32ff",
   "metadata": {},
   "source": [
    "Feed-forward neural networks, or neural networks (NN), are a type of ML algorithm whereby multiple layers, each with many neurons, analyze and process information and then send that information to the next layer, resulting in a final layer that produces a prediction as output "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d7922c",
   "metadata": {},
   "source": [
    "#### Data and Feature Engineering\n",
    "-Dataset is the data that used for training, validating and testing ML model.                         \n",
    "-Training data: data fed to the model during the training process                                     \n",
    "-Validation data: is held out from the training set and used to evaluate how the model is performing after each training. The performance of model on the validation data is used to decide when to stop the training run, and to choose hyperparametes                                                         \n",
    "-Test data: not used in the training process, used to evaluate how the trained model performs. Performance report must be computed on the test data. The error rate on new cases is called the 'generalization error' or out-of-sample error. This value tells how well model will perform on instances it has never seen before. If training error is low (model make few mistakes on training set), but generalization error is high ==> model is overfitting the training data                     \n",
    "-We define structured data as numerical and categorical data                                           \n",
    " +Numerical data includes integer and float values                                                     \n",
    " +Categorical data includes data that can be divided into a finite set of groups, like type of car or education level                                                                                       \n",
    "-Unstructured data, includes data that cannot be represented as neatly. This typically includes free-form text, images, video, audio                                                                       \n",
    "-Data preprocessing or feature engineering (another term), typically includes scaling numerical values, or converting nonnumerical values into a numerical format that can be understood by model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddf740e",
   "metadata": {},
   "source": [
    "-Input describes a single column in dataset before it has been processed                                \n",
    "-Feature describes a single column after it has been processed                                          \n",
    "-Instance is an item to send to the model for prediction. It could be a row in dataset (without the label column), an image to classify, a text document                                                    \n",
    "-Label is the target column in dataset - called 'ground truth label' or output given by model - called 'prediction'                                                                                            \n",
    "-Prediction: the process of sending new data to model and making output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f968e678",
   "metadata": {},
   "source": [
    "#### Machine Learning process/workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc17c7b",
   "metadata": {},
   "source": [
    "-The first step: training - the process of passing training data to model so that it can learn to identify patterns                                                                                      \n",
    "-Next step: testing how the model performs on data outside of training set - 'Model evaluation'           \n",
    "Might run training and testing multiple times, additional feature engineering and adjust model architecture                                                                                            \n",
    "-Final step: 'Serving' - refer to accepting incoming requests and sending back predictions by deploying the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c525e25a",
   "metadata": {},
   "source": [
    "#### Data Drift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d5cc23",
   "metadata": {},
   "source": [
    "Data can change significantly over time. Data drift refers to the challenge of ensuring ML models stay relevant, and that model predictions are an accurate reflection of the environment in which they are being used "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a107d40",
   "metadata": {},
   "source": [
    "#### Poor-Quality Data\n",
    "If some instances are clearly errors, outliers, noise, may to simply discard them or try to fix the errors manually.\n",
    "\n",
    "If some instances are missing a few features/values, there are 3 option:\n",
    "\n",
    "    + ignore these features/values: use drop(axis=1) or dropna() \n",
    "\n",
    "    + fill in the missing values (e.g., with the median): use median() and fillna() \n",
    "    or ask expert's opinion or use Scikit-Learn's class\n",
    "    \n",
    "    + train one model with these features and one model without it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c459408",
   "metadata": {},
   "source": [
    "#### No Free Lunch (NFL) Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f1cbb8",
   "metadata": {},
   "source": [
    "'If make no assumption about the data, then there is no reason to prefer one model over any other'. No model that is a guaranteed to work better. For example, some datasets the best model is linear model, while for other datasets it is a neural network. In practice, make some reasonable assumptions about the data and evaluate only a few reasonable models. \n",
    "The only way to know for sure which model is best is to evaluate them all. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73563b4",
   "metadata": {},
   "source": [
    "## Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2963e7",
   "metadata": {},
   "source": [
    "### Design\n",
    "#### Estimators\n",
    "Any object that can estimate some parameters based on a dataset is called an \"estimator\". The estimation is performed by fit() method, and it take only a dataset as a parameter. Any other parameter needed to guide the estimation process is considered a hyperparameter (such as an imputer's strategy), and it must be set as an instance variable (generally via a contructor parameter)\n",
    "#### Transformers\n",
    "Some estimators can also transform a dataset, they are called \"transformers\". The transformation is performed by transform() method with the dataset to transform as a parameter. It returns the transformed dataset. This transformation generally relies on the learned parameters. All transformers also have method called fit_transform() that is equivalent to calling fit() and then transform()\n",
    "#### Predictors\n",
    "Finally, some estimators, given a dataset, are capable of making predictions, they are called \"predictor\". A predictor has a predict() method that takes a dataset of new instances and return a dataset of corresponding predictions. It also has a score() method that measures the quality of the predictions, given a test set (and the corresponding labels, in the case of supervised learning algorithms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b510103c",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764848d2",
   "metadata": {},
   "source": [
    "The Pipeline constructor takes a list of name/estimator pairs defining a sequence of steps. When we call fit() method of pipeline, it calls fit_transform() sequentially on all transformers, passing the output of each call as the parameter to the next call until it reaches the final estimator, for which it calls the fit() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c46908c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
